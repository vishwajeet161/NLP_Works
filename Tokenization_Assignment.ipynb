{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "432f0bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <DirEntry 'Tokenization.png'>,\n",
       " 1: <DirEntry 'Tokenization.ipynb'>,\n",
       " 2: <DirEntry '.ipynb_checkpoints'>,\n",
       " 3: <DirEntry 'Tokenization_Assignment.ipynb'>,\n",
       " 4: <DirEntry 'text.txt'>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_dict = dict(enumerate(os.scandir()))\n",
    "file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79d7b5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_dict[4]) as f:\n",
    "    text = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85769ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm currently a 4th year student at Graphic Era Deemed to be University, pursuing B Tech in Computer Science with specialization in Artificial Intelligence and Data Science. I have passed the Tensorflow Developer Certificate, AWS Certified Cloud Practitioner and AWS Certified Solution Architect Associate test successfully and earned a badge and certificate😀😃😄😁. I am quite interested in web development and machine learning and have solid front-end knowledge😍🥰. I am going to Tokenize all of these by the order of shivan sir #ChaloCodeKare, #dataScience %$&^ @\\u2068Sanju(Associate Data Scientist)\\u2069.\"]\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a581086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm currently a 4th year student at Graphic Era Deemed to be University, pursuing B Tech in Computer Science with specialization in Artificial Intelligence and Data Science. I have passed the Tensorflow Developer Certificate, AWS Certified Cloud Practitioner and AWS Certified Solution Architect Associate test successfully and earned a badge and certificate😀😃😄😁. I am quite interested in web development and machine learning and have solid front-end knowledge😍🥰. I am going to Tokenize all of these by the order of shivan sir #ChaloCodeKare, #dataScience %$&^ @⁨Sanju(Associate Data Scientist)⁩.\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "text = reduce(lambda a, b : a+str(b), text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2080f54",
   "metadata": {},
   "source": [
    "# Split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85d6d8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm\", 'currently', 'a', '4th', 'year', 'student', 'at', 'Graphic', 'Era', 'Deemed', 'to', 'be', 'University,', 'pursuing', 'B', 'Tech', 'in', 'Computer', 'Science', 'with', 'specialization', 'in', 'Artificial', 'Intelligence', 'and', 'Data', 'Science.', 'I', 'have', 'passed', 'the', 'Tensorflow', 'Developer', 'Certificate,', 'AWS', 'Certified', 'Cloud', 'Practitioner', 'and', 'AWS', 'Certified', 'Solution', 'Architect', 'Associate', 'test', 'successfully', 'and', 'earned', 'a', 'badge', 'and', 'certificate😀😃😄😁.', 'I', 'am', 'quite', 'interested', 'in', 'web', 'development', 'and', 'machine', 'learning', 'and', 'have', 'solid', 'front-end', 'knowledge😍🥰.', 'I', 'am', 'going', 'to', 'Tokenize', 'all', 'of', 'these', 'by', 'the', 'order', 'of', 'shivan', 'sir', '#ChaloCodeKare,', '#dataScience', '%$&^', '@\\u2068Sanju(Associate', 'Data', 'Scientist)\\u2069.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing by word\n",
    "token = text.split()\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f8939265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm currently a 4th year student at Graphic Era Deemed to be University, pursuing B Tech in Computer Science with specialization in Artificial Intelligence and Data Science\",\n",
       " ' I have passed the Tensorflow Developer Certificate, AWS Certified Cloud Practitioner and AWS Certified Solution Architect Associate test successfully and earned a badge and certificate😀😃😄😁',\n",
       " ' I am quite interested in web development and machine learning and have solid front-end knowledge😍🥰',\n",
       " ' I am going to Tokenize all of these by the order of shivan sir #ChaloCodeKare, #dataScience %$&^ @\\u2068Sanju(Associate Data Scientist)\\u2069',\n",
       " '']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing by sentence\n",
    "token1 = text.split('.')\n",
    "token1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63366ac",
   "metadata": {},
   "source": [
    "# Tokenization Using Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a013796d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'm', 'currently', 'a', '4th', 'year', 'student', 'at', 'Graphic', 'Era', 'Deemed', 'to', 'be', 'University', 'pursuing', 'B', 'Tech', 'in', 'Computer', 'Science', 'with', 'specialization', 'in', 'Artificial', 'Intelligence', 'and', 'Data', 'Science', 'I', 'have', 'passed', 'the', 'Tensorflow', 'Developer', 'Certificate', 'AWS', 'Certified', 'Cloud', 'Practitioner', 'and', 'AWS', 'Certified', 'Solution', 'Architect', 'Associate', 'test', 'successfully', 'and', 'earned', 'a', 'badge', 'and', 'certificate', 'I', 'am', 'quite', 'interested', 'in', 'web', 'development', 'and', 'machine', 'learning', 'and', 'have', 'solid', 'front', 'end', 'knowledge', 'I', 'am', 'going', 'to', 'Tokenize', 'all', 'of', 'these', 'by', 'the', 'order', 'of', 'shivan', 'sir', 'ChaloCodeKare', 'dataScience', 'Sanju', 'Associate', 'Data', 'Scientist']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "token2 = re.findall(\"[\\w]+\", text)\n",
    "print(token2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "24107036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm currently a 4th year student at Graphic Era Deemed to be University, pursuing B Tech in Computer Science with specialization in Artificial Intelligence and Data Science\",\n",
       " 'I have passed the Tensorflow Developer Certificate, AWS Certified Cloud Practitioner and AWS Certified Solution Architect Associate test successfully and earned a badge and certificate😀😃😄😁',\n",
       " 'I am quite interested in web development and machine learning and have solid front-end knowledge😍🥰',\n",
       " 'I am going to Tokenize all of these by the order of shivan sir #ChaloCodeKare, #dataScience %$&^ @\\u2068Sanju(Associate Data Scientist)\\u2069.']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens3 = re.compile('[.!?] ').split(text)\n",
    "tokens3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1877728",
   "metadata": {},
   "source": [
    "# Natural Language Toolkit Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9c26787c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting regex>=2021.8.3\n",
      "  Downloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m771.9/771.9 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /home/vishwajeet161/.local/lib/python3.10/site-packages (from nltk) (1.3.1)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2023.8.8 tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --user -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c83c30f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/vishwajeet161/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4d5578a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'m\", 'currently', 'a', '4th', 'year', 'student', 'at', 'Graphic', 'Era', 'Deemed', 'to', 'be', 'University', ',', 'pursuing', 'B', 'Tech', 'in', 'Computer', 'Science', 'with', 'specialization', 'in', 'Artificial', 'Intelligence', 'and', 'Data', 'Science', '.', 'I', 'have', 'passed', 'the', 'Tensorflow', 'Developer', 'Certificate', ',', 'AWS', 'Certified', 'Cloud', 'Practitioner', 'and', 'AWS', 'Certified', 'Solution', 'Architect', 'Associate', 'test', 'successfully', 'and', 'earned', 'a', 'badge', 'and', 'certificate😀😃😄😁', '.', 'I', 'am', 'quite', 'interested', 'in', 'web', 'development', 'and', 'machine', 'learning', 'and', 'have', 'solid', 'front-end', 'knowledge😍🥰', '.', 'I', 'am', 'going', 'to', 'Tokenize', 'all', 'of', 'these', 'by', 'the', 'order', 'of', 'shivan', 'sir', '#', 'ChaloCodeKare', ',', '#', 'dataScience', '%', '$', '&', '^', '@', '\\u2068Sanju', '(', 'Associate', 'Data', 'Scientist', ')', '\\u2069', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk_token = word_tokenize(text)\n",
    "print(nltk_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e9f65c",
   "metadata": {},
   "source": [
    "# Punctuation based tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ed2ab9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'\", 'm', 'currently', 'a', '4th', 'year', 'student', 'at', 'Graphic', 'Era', 'Deemed', 'to', 'be', 'University', ',', 'pursuing', 'B', 'Tech', 'in', 'Computer', 'Science', 'with', 'specialization', 'in', 'Artificial', 'Intelligence', 'and', 'Data', 'Science', '.', 'I', 'have', 'passed', 'the', 'Tensorflow', 'Developer', 'Certificate', ',', 'AWS', 'Certified', 'Cloud', 'Practitioner', 'and', 'AWS', 'Certified', 'Solution', 'Architect', 'Associate', 'test', 'successfully', 'and', 'earned', 'a', 'badge', 'and', 'certificate', '😀😃😄😁.', 'I', 'am', 'quite', 'interested', 'in', 'web', 'development', 'and', 'machine', 'learning', 'and', 'have', 'solid', 'front', '-', 'end', 'knowledge', '😍🥰.', 'I', 'am', 'going', 'to', 'Tokenize', 'all', 'of', 'these', 'by', 'the', 'order', 'of', 'shivan', 'sir', '#', 'ChaloCodeKare', ',', '#', 'dataScience', '%$&^', '@\\u2068', 'Sanju', '(', 'Associate', 'Data', 'Scientist', ')\\u2069.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "punct_token = wordpunct_tokenize(text)\n",
    "print(punct_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2ce8547e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm currently a 4th year student at Graphic Era Deemed to be University, pursuing B Tech in Computer Science with specialization in Artificial Intelligence and Data Science.\",\n",
       " 'I have passed the Tensorflow Developer Certificate, AWS Certified Cloud Practitioner and AWS Certified Solution Architect Associate test successfully and earned a badge and certificate😀😃😄😁.',\n",
       " 'I am quite interested in web development and machine learning and have solid front-end knowledge😍🥰.',\n",
       " 'I am going to Tokenize all of these by the order of shivan sir #ChaloCodeKare, #dataScience %$&^ @\\u2068Sanju(Associate Data Scientist)\\u2069.']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sen_token = sent_tokenize(text)\n",
    "sen_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cf292ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm\", 'currently', 'a', '4th', 'year', 'student', 'at', 'Graphic', 'Era', 'Deemed', 'to', 'be', 'University', ',', 'pursuing', 'B', 'Tech', 'in', 'Computer', 'Science', 'with', 'specialization', 'in', 'Artificial', 'Intelligence', 'and', 'Data', 'Science', '.', 'I', 'have', 'passed', 'the', 'Tensorflow', 'Developer', 'Certificate', ',', 'AWS', 'Certified', 'Cloud', 'Practitioner', 'and', 'AWS', 'Certified', 'Solution', 'Architect', 'Associate', 'test', 'successfully', 'and', 'earned', 'a', 'badge', 'and', 'certificate', '😀', '😃', '😄', '😁', '.', 'I', 'am', 'quite', 'interested', 'in', 'web', 'development', 'and', 'machine', 'learning', 'and', 'have', 'solid', 'front-end', 'knowledge', '😍', '🥰', '.', 'I', 'am', 'going', 'to', 'Tokenize', 'all', 'of', 'these', 'by', 'the', 'order', 'of', 'shivan', 'sir', '#ChaloCodeKare', ',', '#dataScience', '%', '$', '&', '^', '@', '\\u2068', 'Sanju', '(', 'Associate', 'Data', 'Scientist', ')', '\\u2069', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "tweet_token = TweetTokenizer()\n",
    "print(tweet_token.tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ef334e",
   "metadata": {},
   "source": [
    "# SpaCy using Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c62627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /home/vishwajeet161/.local/lib/python3.10/site-packages (3.6.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (59.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (2.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (2.3.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (8.1.12)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: jinja2 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (1.25.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (0.10.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.6.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/lib/python3/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->spacy) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46385e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.25.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: jinja2 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (59.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.6.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2020.6.20)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/lib/python3/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.6.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "587c6f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'m\", 'currently', 'a', '4th', 'year', 'student', 'at', 'Graphic', 'Era', 'Deemed', 'to', 'be', 'University', ',', 'pursuing', 'B', 'Tech', 'in', 'Computer', 'Science', 'with', 'specialization', 'in', 'Artificial', 'Intelligence', 'and', 'Data', 'Science', '.', 'I', 'have', 'passed', 'the', 'Tensorflow', 'Developer', 'Certificate', ',', 'AWS', 'Certified', 'Cloud', 'Practitioner', 'and', 'AWS', 'Certified', 'Solution', 'Architect', 'Associate', 'test', 'successfully', 'and', 'earned', 'a', 'badge', 'and', 'certificate', '😀', '😃', '😄', '😁', '.', 'I', 'am', 'quite', 'interested', 'in', 'web', 'development', 'and', 'machine', 'learning', 'and', 'have', 'solid', 'front', '-', 'end', 'knowledge', '😍', '🥰', '.', 'I', 'am', 'going', 'to', 'Tokenize', 'all', 'of', 'these', 'by', 'the', 'order', 'of', 'shivan', 'sir', '#', 'ChaloCodeKare', ',', '#', 'dataScience', '%', '$', '&', '^', '@\\u2068Sanju(Associate', 'Data', 'Scientist)\\u2069.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "my_doc = nlp(text)\n",
    "\n",
    "token_list = []\n",
    "for token in my_doc:\n",
    "    token_list.append(token.text)\n",
    "\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad5a0853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-md==3.6.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.6.0/en_core_web_md-3.6.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from en-core-web-md==3.6.0) (3.6.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.25.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.1.12)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.4.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.9)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (6.3.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.10.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.31.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.66.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.0.8)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.9.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.1.2)\n",
      "Requirement already satisfied: jinja2 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (59.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (23.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.3.0)\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.6.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (4.7.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2020.6.20)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.7.10)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/vishwajeet161/.local/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (0.1.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/lib/python3/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-md==3.6.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.6.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_md "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4c16c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'m\", 'currently', 'a', '4th', 'year', 'student', 'at', 'Graphic', 'Era', 'Deemed', 'to', 'be', 'University', ',', 'pursuing', 'B', 'Tech', 'in', 'Computer', 'Science', 'with', 'specialization', 'in', 'Artificial', 'Intelligence', 'and', 'Data', 'Science', '.', 'I', 'have', 'passed', 'the', 'Tensorflow', 'Developer', 'Certificate', ',', 'AWS', 'Certified', 'Cloud', 'Practitioner', 'and', 'AWS', 'Certified', 'Solution', 'Architect', 'Associate', 'test', 'successfully', 'and', 'earned', 'a', 'badge', 'and', 'certificate', '😀', '😃', '😄', '😁', '.', 'I', 'am', 'quite', 'interested', 'in', 'web', 'development', 'and', 'machine', 'learning', 'and', 'have', 'solid', 'front', '-', 'end', 'knowledge', '😍', '🥰', '.', 'I', 'am', 'going', 'to', 'Tokenize', 'all', 'of', 'these', 'by', 'the', 'order', 'of', 'shivan', 'sir', '#', 'ChaloCodeKare', ',', '#', 'dataScience', '%', '$', '&', '^', '@\\u2068Sanju(Associate', 'Data', 'Scientist)\\u2069.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "640e3554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm currently a 4th year student at Graphic Era Deemed to be University, pursuing B Tech in Computer Science with specialization in Artificial Intelligence and Data Science.\n",
      "I have passed the Tensorflow Developer Certificate, AWS Certified Cloud Practitioner and AWS Certified Solution Architect Associate test successfully and earned a badge and certificate😀😃😄😁.\n",
      "I am quite interested in web development and machine learning and have solid front-end knowledge😍🥰.\n",
      "I am going to Tokenize all of these by the order of shivan sir #ChaloCodeKare, #dataScience %$&^ @⁨Sanju(Associate\n",
      "Data Scientist)⁩.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "457b9b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm currently a 4th year student at Graphic Era Deemed to be University, pursuing B Tech in Computer Science with specialization in Artificial Intelligence and Data Science.\", 'I have passed the Tensorflow Developer Certificate, AWS Certified Cloud Practitioner and AWS Certified Solution Architect Associate test successfully and earned a badge and certificate😀😃😄😁.', 'I am quite interested in web development and machine learning and have solid front-end knowledge😍🥰.', 'I am going to Tokenize all of these by the order of shivan sir #ChaloCodeKare, #dataScience %$&^ @\\u2068Sanju(Associate Data Scientist)\\u2069.']\n"
     ]
    }
   ],
   "source": [
    "nlp1 = English()\n",
    "nlp1.add_pipe('sentencizer')\n",
    "\n",
    "doc1 = nlp1(text)\n",
    "\n",
    "sentence_list =[]\n",
    "for sentence in doc1.sents:\n",
    "    sentence_list.append(sentence.text)\n",
    "print(sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9dc37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
